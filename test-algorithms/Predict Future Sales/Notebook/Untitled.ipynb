{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\lucas\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\lucas\\Anaconda2\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import nltk, datetime\n",
    "\n",
    "train = pd.read_csv('../data/sales_train_v2.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "items = pd.read_csv('../data/items.csv')\n",
    "item_cats = pd.read_csv('../data/item_categories.csv')\n",
    "shops = pd.read_csv('../data/shops.csv')\n",
    "print('train:', train.shape, 'test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data present on train dataset and not in test dataset\n",
    "\n",
    "[c for c in train.columns if c not in test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Features\n",
    "feature_cnt = 25\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\n",
    "items['item_name_len'] = items['item_name'].map(len) #Lenth of Item Description\n",
    "items['item_name_wc'] = items['item_name'].map(lambda x: len(str(x).split(' '))) #Item Description Word Count\n",
    "txtFeatures = pd.DataFrame(tfidf.fit_transform(items['item_name']).toarray())\n",
    "cols = txtFeatures.columns\n",
    "for i in range(feature_cnt):\n",
    "    items['item_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Features\n",
    "feature_cnt = 25\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\n",
    "item_cats['item_category_name_len'] = item_cats['item_category_name'].map(len)  #Lenth of Item Category Description\n",
    "item_cats['item_category_name_wc'] = item_cats['item_category_name'].map(lambda x: len(str(x).split(' '))) #Item Category Description Word Count\n",
    "txtFeatures = pd.DataFrame(tfidf.fit_transform(item_cats['item_category_name']).toarray())\n",
    "cols = txtFeatures.columns\n",
    "for i in range(feature_cnt):\n",
    "    item_cats['item_category_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\n",
    "item_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Features\n",
    "feature_cnt = 25\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\n",
    "shops['shop_name_len'] = shops['shop_name'].map(len)  #Lenth of Shop Name\n",
    "shops['shop_name_wc'] = shops['shop_name'].map(lambda x: len(str(x).split(' '))) #Shop Name Word Count\n",
    "txtFeatures = pd.DataFrame(tfidf.fit_transform(shops['shop_name']).toarray())\n",
    "cols = txtFeatures.columns\n",
    "for i in range(feature_cnt):\n",
    "    shops['shop_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Monthly\n",
    "train['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "train = train.drop(['date','item_price'], axis=1)\n",
    "train = train.groupby([c for c in train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\n",
    "train = train.rename(columns={'item_cnt_day':'item_cnt_month'})\n",
    "#Monthly Mean\n",
    "shop_item_monthly_mean = train[['shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'], as_index=False)[['item_cnt_month']].mean()\n",
    "shop_item_monthly_mean = shop_item_monthly_mean.rename(columns={'item_cnt_month':'item_cnt_month_mean'})\n",
    "#Add Mean Feature\n",
    "train = pd.merge(train, shop_item_monthly_mean, how='left', on=['shop_id','item_id'])\n",
    "#Last Month (Oct 2015)\n",
    "shop_item_prev_month = train[train['date_block_num']==33][['shop_id','item_id','item_cnt_month']]\n",
    "shop_item_prev_month = shop_item_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\n",
    "shop_item_prev_month.head()\n",
    "#Add Previous Month Feature\n",
    "train = pd.merge(train, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n",
    "#Items features\n",
    "train = pd.merge(train, items, how='left', on='item_id')\n",
    "#Item Category features\n",
    "train = pd.merge(train, item_cats, how='left', on='item_category_id')\n",
    "#Shops features\n",
    "train = pd.merge(train, shops, how='left', on='shop_id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [c for c in train.columns if c not in ['item_cnt_month']]\n",
    "#Validation Hold Out Month\n",
    "x1 = train[train['date_block_num']<33]\n",
    "y1 = np.log1p(x1['item_cnt_month'].clip(0.,20.))\n",
    "x1 = x1[col]\n",
    "x2 = train[train['date_block_num']==33]\n",
    "y2 = np.log1p(x2['item_cnt_month'].clip(0.,20.))\n",
    "x2 = x2[col]\n",
    "\n",
    "reg = ensemble.ExtraTreesRegressor(n_estimators=25, n_jobs=-1, max_depth=15, random_state=18)\n",
    "reg.fit(x1,y1)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.),reg.predict(x2).clip(0.,20.))))\n",
    "#full train\n",
    "reg.fit(train[col],train['item_cnt_month'].clip(0.,20.))\n",
    "test['item_cnt_month'] = reg.predict(test[col]).clip(0.,20.)\n",
    "test[['ID','item_cnt_month']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
